---
title: Průvodce přesunutím pojistných rizik do Azure
author: scseely
ms.author: scseely
ms.date: 11/20/2019
ms.topic: article
ms.service: industry
description: Jak může vývojář obit přesunout existující řešení do Azure a podpořit podpůrnou infrastrukturu.
ms.openlocfilehash: 456c054cf3a6165f160005ba8ea2c155637faa07
ms.sourcegitcommit: 3b175d73a82160c4cacec1ce00c6d804a93c765d
ms.translationtype: MT
ms.contentlocale: cs-CZ
ms.lasthandoff: 02/06/2020
ms.locfileid: "77052667"
---
# <a name="actuarial-risk-analysis-and-financial-modeling-solution-guide"></a>Průvodce řešením rizikového obhodnocení rizika a finanční modelování

Za posledních několik let se nemuseli brát v úvahu několik nových předpisů. Tato nová nařízení vyžadují pro pojistitele rozsáhlejší finanční modelování. Vydaná [platební schopnost](https://eur-lex.europa.eu/legal-content/EN/ALL/?uri=celex%3A32009L0138) v rámci Evropské unie, která vyžaduje, aby provedla příslušné pojišťovny k ověření, že pojistitel bude mít na konci roku rozpouštědlo. Pojistitelé, kteří poskytují proměnnou Annuities, musí dodržovat [pojistkou pojistně XLIII](https://eur-lex.europa.eu/legal-content/EN/ALL/?uri=celex%3A32009L0138) s rozsáhlou analýzou hotovostních toků a peněžních toků. Všechny typy pojistitelů, včetně těch, kteří distribuují pojištění jako produkty, budou muset implementovat [mezinárodní finanční vykazování Standard 17](https://www.ifrs.org/supporting-implementation/supporting-materials-by-ifrs-standard/ifrs-17/) (IFRS 17) o 2021. Jiné předpisy existují v závislosti na tom, v jaké jurisdikci pracují pojistitelé. Tyto normy a předpisy vyžadují Pojistní matematici, aby při modelování prostředků a pasiv používaly výpočetní techniky náročné na výpočetní výkon. Mnohé z analýz využívají stochastically vygenerovaná data scénáře pro seriatim vstupy věcí, jako jsou aktiva a závazky. Kromě zákonných potřeb Pojistní matematici k vygenerování vstupních tabulek pro modely, které vytvářejí sestavy, korektní množství finančních modelování a výpočtů. Interní mřížky nesplňují výpočetní potřeby, takže Pojistní matematici se neustále přesouvá do cloudu.

Pojistní matematici přejděte do cloudu a získejte víc času na kontrolu, vyhodnocení a ověření výsledků. V případě, že se regulační orgány auditují, Pojistní matematici musí být schopni vysvětlit jejich výsledky. Přechod do cloudu poskytuje přístup k výpočetním prostředkům, aby bylo možné spouštět 20000 hodin analýzy během 24-120 hodin hodinového času v důsledku paralelismu. Pro pomoc s tím, jak je potřeba škálovat, mnoho společností, které vytvářejí obdobu softwaru, poskytují řešení, které umožňuje provádět výpočty v Azure. Některá z těchto řešení jsou postavená na technologiích, které běží místně a v Azure jako [sada HPC Pack](https://docs.microsoft.com/powershell/high-performance-computing/overview?view=hpc16-ps&WT.mc_id=riskmodel-docs-scseely). Jiné jsou nativní Azure a používají [Azure Batch](https://docs.microsoft.com/azure/batch?WT.mc_id=riskmodel-docs-scseely), [Virtual Machine Scale Sets](https://docs.microsoft.com/azure/virtual-machine-scale-sets?WT.mc_id=riskmodel-docs-scseely)nebo vlastní řešení škálování.

V tomto článku se podíváme na to, jak můžou vývojáři používat Azure společně s balíčky pro modelování k analýze rizik. Tento článek popisuje některé technologie Azure, které používají balíčky modelování ke spouštění ve velkém měřítku v Azure. Stejnou technologii můžete použít k další analýze dat. Podíváme se na následující položky:

- Spouštění větších modelů v Azure za kratší dobu.
- Vytváření sestav o výsledcích
- Správa uchovávání dat.

Bez ohledu na to, jestli spravujete život, nemovitosti a nucené, zdravotní nebo jiné pojištění, potřebujete vytvořit finanční a rizikové modely svých assetů a závazků, abyste mohli upravovat své investice a Premium, abyste měli přehled o tom, jak se jedná o pojistitele. Vytváření sestav IFRS 17 přidává změny modelů, které Pojistní matematici vytvoří, jako je například výpočet smluvní marže služby (CSM), který mění způsob, jakým pojistitelé spravují svůj zisk v čase.

## <a name="running-more-in-less-time-in-azure"></a>Spuštění více za méně času v Azure

Domníváte se, že jste proslibem cloudu: můžete rychleji a snadněji spustit vaše finanční a rizikové modely. U mnoha pojistitelů se na konci výpočtu obálky zobrazuje problém: k provedení těchto výpočtů od začátku do konce budou potřebovat roky nebo dokonce desetiletí po sobě jdoucí dobu. K vyřešení problému za běhu potřebujete technologii. Vaše strategie:

- Příprava dat: pomalé změny dat. Jakmile je zásada nebo kontrakt služby v platnosti, nároky se pohybují předvídatelným tempem. Můžete připravit data potřebná ke spuštění modelu při jejich dochodu, což eliminuje nutnost plánování mnohem času pro čištění a přípravu dat. Clustering můžete použít také k vytvoření seriatimch pro data prostřednictvím vážené reprezentace. Méně záznamů obvykle vede ke zkrácení času výpočtu.
- Paralelní: Pokud potřebujete provést stejnou analýzu na dvě nebo více položek, možná budete moct analyzovat současně.

Pojďme se podívat na tyto položky jednotlivě.

### <a name="data-preparation"></a>Příprava dat

Data se budou natékat z několika různých zdrojů. Máte částečně strukturovaná data zásad v knihách firmy. Informace o pojištěných osobách, společnostech a položkách, které se zobrazí v různých formulářích aplikace. Generátory ekonomických scénářů (ESGs) vytvářejí data v nejrůznějších formátech, které mohou vyžadovat převod do formuláře, který váš model může použít. Aktuální data na hodnotách assetů také potřebují normalizaci. Data o zásobách na trhu, data peněžního toku na splátkách, platební údaje na hypotékách a další data prostředků vyžadují při přechodu ze zdroje do modelu nějakou přípravu. Nakonec byste měli aktualizovat jakékoli předpoklady na základě dat o nedávných zkušenostech. Chcete-li zrychlit spuštění modelu, připravte data před časem. Pokud k tomu dojde, provedete všechny potřebné aktualizace, které chcete přidat do změn od poslední plánované aktualizace. j

Jak tedy připravíte data? Nejprve se podíváme na běžné bity a podívejte se, jak pracovat s různými způsoby, jak se data zobrazí. Nejdřív budete chtít, aby měl mechanismus získat všechny změny od poslední synchronizace. Tento mechanismus by měl obsahovat hodnotu, která se může seřadit. V případě nedávných změn by tato hodnota měla být větší než jakákoli předchozí změna. Dva nejběžnější dva mechanismy jsou stále rostoucí pole ID nebo časové razítko. Pokud má záznam rostoucí klíč ID, ale zbytek záznamu obsahuje pole, která je možné aktualizovat, je nutné použít například &quot;poslední změny&quot; časové razítko k vyhledání změn. Po zpracování záznamů si zaznamenejte hodnotu, kterou poslední položka aktualizovala. Tato hodnota, pravděpodobně časové razítko v poli s názvem _LastModified_, se zobrazí jako vodoznak, který se použije pro další dotazy v úložišti dat. Změny dat lze zpracovat mnoha způsoby. Tady jsou dva běžné mechanismy, které používají minimální prostředky:

1. Pokud máte stovky nebo tisíce změn, které se mají zpracovat: Nahrajte data do úložiště objektů BLOB. Použijte Trigger události v [Azure Data Factory](https://docs.microsoft.com/azure/data-factory?WT.mc_id=riskmodel-docs-scseely) ke zpracování sady změn.
2. Pokud máte malé sady změn ke zpracování nebo chcete data aktualizovat, jakmile dojde ke změně, vložte každou změnu do zprávy ve frontě hostované [Service Bus](https://docs.microsoft.com/azure/service-bus-messaging?WT.mc_id=riskmodel-docs-scseely) nebo [frontami úložiště](https://docs.microsoft.com/azure/storage/queues/storage-queues-introduction?WT.mc_id=riskmodel-docs-scseely). [Tento článek](https://docs.microsoft.com/azure/service-bus-messaging/service-bus-azure-and-service-bus-queues-compared-contrasted?WT.mc_id=riskmodel-docs-scseely) obsahuje Skvělé vysvětlení kompromisů mezi těmito dvěma technologiemi. Jakmile je zpráva ve frontě, můžete ke zpracování zprávy použít Trigger v Azure Functions nebo Azure Data Factory.

Následující obrázek znázorňuje typický scénář. Nejdřív naplánovaná úloha shromáždí určitou sadu dat a umístí soubor do úložiště. Naplánovanou úlohou může být úloha CRON běžící místně, [úloha Scheduleru](https://docs.microsoft.com/azure/scheduler?WT.mc_id=riskmodel-docs-scseely), [Aplikace logiky](https://docs.microsoft.com/azure/logic-apps/logic-apps-overview?WT.mc_id=riskmodel-docs-scseely)nebo cokoli, co běží na časovači. Po nahrání souboru může být instance [funkce Azure Function](https://docs.microsoft.com/azure/azure-functions?WT.mc_id=riskmodel-docs-scseely) nebo **Data Factory** spuštěná ke zpracování dat. Pokud soubor lze zpracovat v krátkém časovém intervalu, použijte **funkci**. Pokud je zpracování složité, vyžaduje AI nebo jiné složité skriptování, možná zjistíte, že [HDInsight](https://docs.microsoft.com/azure/hdinsight?WT.mc_id=riskmodel-docs-scseely), [Azure Databricks](https://docs.microsoft.com/azure/azure-databricks?WT.mc_id=riskmodel-docs-scseely)nebo něco vlastního funguje lépe. Po dokončení se soubor vítr do použitelného formuláře jako nový soubor nebo jako záznamy v databázi.

 ![](./assets/insurance-risk-assets/process-files.png)

Jakmile jsou data v Azure, je potřeba, aby ji aplikace pro modelování mohla použít. Můžete napsat kód pro vlastní transformace, spustit položky prostřednictvím služby **HDInsight** nebo **cihly Azure datacihly** k ingestování větších položek nebo zkopírovat data do správných datových sad. Použití nástrojů pro velké objemy dat vám také může přispět k transformaci nestrukturovaných dat na strukturovaná data a ke spouštění všech souborů AI a ML přes přijatá data. Můžete také hostovat virtuální počítače, nahrávat data přímo do zdrojů dat z místního, volat Azure Functions přímo atd.

Později je potřeba data spotřebovat pomocí vašich modelů. Způsob, jakým to provedete, závisí hlavně na tom, jak výpočty potřebují přístup k datům. Některé systémy modelování vyžadují, aby všechny datové soubory byly živé na uzlu, na kterém je výpočet spuštěný. Jiní uživatelé můžou používat databáze, jako je [Azure SQL Database](https://docs.microsoft.com/azure/sql-database/?WT.mc_id=riskmodel-docs-scseely), [MySQL](https://docs.microsoft.com/azure/mysql/?WT.mc_id=riskmodel-docs-scseely)nebo [PostgreSQL](https://docs.microsoft.com/azure/postgresql/?WT.mc_id=riskmodel-docs-scseely). Můžete použít méně nákladnou verzi některé z těchto položek a následně škálovat výkon během spuštění modelování. Získáte tak cenu, kterou potřebujete ke každé každodenní práci, a navíc i dodatečnou rychlost, jenom když tisíce jader požadují data. Normálně budou tato data při spuštění modelování jen pro čtení. Pokud k výpočtům dochází v několika oblastech, zvažte použití [Cosmos DB](https://docs.microsoft.com/azure/cosmos-db/distribute-data-globally?WT.mc_id=riskmodel-docs-scseely) nebo [geografické replikace Azure SQL](https://docs.microsoft.com/azure/sql-database/sql-database-geo-replication-overview?WT.mc_id=riskmodel-docs-scseely). Oba poskytují mechanismy pro automatickou replikaci dat mezi oblastmi s nízkou latencí. Vaše volba závisí na nástrojích, které vývojáři znají, jak máte modelovat data a kolik oblastí jste použili pro spuštění modelování.

Věnujte vám nějaký čas na místo, kde se data ukládají. Pochopte, kolik souběžných požadavků na stejná data budou existovat. Zamyslete se nad tím, jak budete tyto informace distribuovat:

- Získá každý výpočetní uzel svou vlastní kopii?
- Sdílí se kopírování v rámci určitého umístění s velkou šířkou pásma?

Pokud udržujete data centralizovaná pomocí Azure SQL, pravděpodobně budete databázi uchovávat na nižší úrovni. Pokud se data používají jenom během spuštění modelování a neaktualizují se velmi často, zákazníci Azure budou v této době k zálohování dat a vypnutí instancí databáze v mezi nimi. Potenciální úspory jsou velké. Zákazníci můžou také využívat [elastické fondy Azure SQL](https://docs.microsoft.com/azure/sql-database/sql-database-elastic-pool?WT.mc_id=riskmodel-docs-scseely). Jsou určené k řízení nákladů na databázi, zejména pokud nevíte, které databáze budou v různých časech zatíženy velkým objemem zátěže. Elastické fondy umožňují, aby kolekce databází používala tolik energie, kolik potřebuje, a pak se po přesunu na jiné místo v systému přejdou na jiné úrovni.

Při spuštění modelování možná budete muset zakázat synchronizaci dat, aby výpočty později v procesu používaly stejná data. Pokud používáte službu Řízení front, zakažte procesory zpráv, ale umožněte, aby fronty přijímaly data.

Můžete také použít čas před spuštěním ke generování hospodářských scénářů, aktualizaci matematických předpokladů a obecně aktualizovat jiná statická data. Pojďme se podívat na ESG (ekonomické scénáře generace). [Společnost Pojistní matematici](https://www.soa.org/) poskytuje [generátor Academy pro úrokové sazby](https://www.soa.org/tables-calcs-tools/research-scenario/) (AIRG), což je ESG které modely U. S. Výnosy z pokladny. AIRG je předepsáno pro použití v položkách, jako je ocenění ruční 20 (VM-20) výpočtů. Jiní ESGs můžou modelovat burzovní trh, hypotéky, komoditní ceny a tak dále.

Vzhledem k tomu, že vaše prostředí ispreprocessing data, můžete také spustit další části. Můžete mít například věci, které yv1ou model, který používá záznamy k reprezentaci větších populací. To obvykle dělá díky clusteringu záznamy. Pokud je datová sada zřídka aktualizovaná, například jednou denně, může snížit sadu záznamů na to, co bude v modelu použito jako součást procesu příjmu.

Pojďme se podívat na praktický příklad. V IFRS-17 je potřeba seskupit své smlouvy tak, aby maximální vzdálenost mezi počátečními daty pro jakékoli dvě smlouvy byla v jednom roce. Řekněme, že to uděláte snadno a jako mechanismus seskupení použijete rok smlouvy. Tato segmentace se dá udělat, když se data načtou do Azure, a to tak, že si projdeme soubor a přesunete záznamy do odpovídajících skupin roků.

Zaměření na přípravu dat zkracuje dobu potřebnou ke spuštění komponent modelu. Získáním dat v brzké době můžete ušetřit čas při spouštění vašich modelů.

### <a name="parallelization"></a>Paralelizace

Řádné paralelismuy kroků může výrazně zkrátit čas spuštění. K tomuto zrychlení dochází díky zjednodušení částí, které implementujete, a znalost způsobu, jak tento model vyjádřit způsobem, který umožňuje souběžně spustit dvě nebo více aktivit. Štych je najít rovnováhu mezi velikostí pracovní žádosti a produktivitou jednotlivých uzlů. Pokud se úkol v průběhu instalace a vyčištění vymění rychleji než při vyhodnocování, je to moc malé. Pokud je úloha příliš velká, doba provádění se nevylepšuje. Chcete, aby byla aktivita dostatečně malá pro rozprostření přes více uzlů a aby se v uplynulém čase provádění zajistil kladný rozdíl.

Abyste mohli využít svůj systém na maximum, musíte pochopit pracovní postup pro svůj model a způsob, jakým jsou výpočty v interakci s možností horizontálního navýšení kapacity. Váš software může mít fiktivní úlohy, úkoly nebo něco podobného. Pomocí těchto znalostí můžete navrhnout něco, co může rozdělit práci. Pokud máte ve svém modelu některé vlastní kroky, navrhněte je, aby se vstupy mohly rozdělit do menších skupin ke zpracování. Často, tento postup se označuje jako model bodového shromažďování.

- Bodový: rozdělte vstupy na přirozené řádky a umožněte spuštění samostatných úloh.
- Shromáždění: Jakmile jsou úkoly dokončené, shromážděte jejich výstupy.

Při rozdělování informací také Zjistěte, kde se proces musí synchronizovat, než se posune. Existuje několik běžných míst, co lidé rozdělí. Pro vnořené stochastického běhy můžete mít tisíce vnějších smyček se sadou inflexních bodů, které spouštějí vnitřní smyčky scénářů 100. Každá vnější smyčka může běžet současně. Zastavíte se v inflexovém bodu, potom spustíte vnitřní smyčky současně, vrátíte informace, abyste upravili data pro vnější smyčku, a pak se znovu přihlásíte. Následující obrázek znázorňuje pracovní postup. Vzhledem k dostatečné výpočetní zátěži můžete spustit vnitřní smyčky 100 000 na 100 000 jádrech a prodloužit dobu zpracování do součtu následujících dob:

![](./assets/insurance-risk-assets/timing.png)

Distribuce bude narůstat v závislosti na tom, jak se to dělá. může to být jednoduché, jak vytvořit malou úlohu se správnými parametry nebo jako složitou jako kopírování souborů 100 tisíc na správné místo. Výsledky zpracování můžete dokonce urychlit, i když můžete agregaci výsledků distribuovat pomocí Apache Spark z HD Insight, Azure Databricks nebo vlastního nasazení. Například výpočetní průměry jsou jednoduchou skutečností pro pamatujce si počet položek, které jsou tak daleko a součet. Jiné výpočty můžou pracovat lépe na jednom počítači s tisíci jader. U těchto počítačů můžete používat počítače s podporou GPU v Azure.

Většina matematických týmů tuto cestu zahájí přesunutím jejich modelů do Azure. Pak shromažďují data časování v různých krocích procesu. Pak seřadí čas všech kroků od nejdéle po nejkratší uplynulý čas. Neuvidí celkovou dobu provádění, protože něco může spotřebovat tisíce základních hodin, ale jenom 20 minut uplynulo čas. Pro každý z nejdelších spuštěných kroků úlohy hledají vývojáři nezávisle na způsobech, jak zkrátit uplynulý čas při získávání správných výsledků. Tento proces se pravidelně opakuje. Někteří pojistí týmy nastaví cílový čas spuštění. řekněme, že analýza po noci má za následek běhu za méně než 8 hodin. Jakmile se čas překročí 8,25 hodin, některá část neobvyklého týmu přepne, aby se zlepšil čas nejdelšího kusu v analýze. Jakmile se čas vrátí do 7,5 hodin, přepnou zpět na vývoj. Heuristiky pro návrat a optimalizaci se liší mezi Pojistní matematici.

Pokud to chcete spustit, máte několik možností. Nejdůležitější software pracuje s výpočetními mřížkami. Mřížky, které fungují místně a v Azure, používají buď [sadu HPC Pack](https://docs.microsoft.com/azure/virtual-machines/windows/hpcpack-cluster-options?WT.mc_id=riskmodel-docs-scseely), balíček třetí strany, nebo něco vlastního. Mřížky optimalizované pro Azure budou používat [Virtual Machine Scale Sets](https://docs.microsoft.com/azure/virtual-machine-scale-sets/?WT.mc_id=riskmodel-docs-scseely), [Batch](https://docs.microsoft.com/azure/batch/?WT.mc_id=riskmodel-docs-scseely)nebo něco vlastního. Pokud se rozhodnete použít buď sady škálování nebo služby Batch, ujistěte se, že se podíváte na podporu virtuálních počítačů s nízkou prioritou ([škálování sady](https://docs.microsoft.com/azure/virtual-machine-scale-sets/virtual-machine-scale-sets-use-low-priority?WT.mc_id=riskmodel-docs-scseely) s nízkou prioritou, dokumentace s nízkou prioritou služby [Batch](https://docs.microsoft.com/azure/batch/batch-low-pri-vms?WT.mc_id=riskmodel-docs-scseely) ). Virtuální počítač s nízkou prioritou je virtuální počítač, na kterém je spuštěný hardware, který můžete pronajmout za běžnou cenu. Nižší cena je k dispozici, protože virtuální počítače s nízkou prioritou mohou být přerušeny, pokud je kapacita vyžaduje. Pokud máte ve svém časovém rozpočtu nějaké Wiggle místnosti, virtuální počítače s nízkou prioritou poskytují skvělý způsob, jak snížit cenu spuštění modelování.

Pokud potřebujete koordinovat spouštění a nasazování napříč mnoha počítači, možná s některými běžícími v různých oblastech, můžete využít výhod CycleCloud. CycleCloud náklady neobsahují nic navíc. V případě potřeby orchestruje přesun dat. To zahrnuje přidělení, monitorování a vypnutí počítačů. Může dokonce zpracovávat i počítače s nízkou prioritou a zajistit, aby byly výdaje obsaženy. Můžete tak učinit, abyste popsali kombinaci počítačů, které potřebujete. Například možná budete potřebovat třídu Machine, ale můžete ji také spustit na všech verzích, které mají 2 nebo více jader. Cyklus dokáže přidělit jádra mezi tyto typy počítačů.

## <a name="reporting-on-the-results"></a>Vytváření sestav o výsledcích

Po spuštění a vytvoření výsledků pro balíčky s matematickým zápisem budete mít k dispozici několik sestav regulátorů. Budete mít také Horská oblast nových dat, která budete možná chtít analyzovat, aby se vygenerovaly přehledy, které nejsou vyžadovány regulačními orgány nebo auditory. Možná budete chtít pochopit profil vašich nejlepších zákazníků. S využitím přehledů můžete sdělit, co zákazník s nízkými náklady vypadá, aby ho zákazníci a prodej mohli rychleji najít. Podobně můžete data použít k zjištění, které skupiny mají výhodu z toho, aby měli pojištění na maximum. Můžete například zjistit, že uživatelé, kteří využívají výhod ročního fyzického problému, se dříve dozvěděli o problémech se stavem rané fáze. Tím ušetříte čas a peníze pojišťovací společnosti. Tato data můžete použít k řízení chování v základu zákazníka.

K tomu budete mít přístup k mnoha nástrojům pro datové vědy a také k některým částem pro vizualizaci. V závislosti na tom, kolik šetření chcete udělat, můžete začít s [Data Science VM](https://docs.microsoft.com/azure/machine-learning/data-science-virtual-machine/overview?WT.mc_id=riskmodel-docs-scseely) , kterou je možné zřídit z Azure Marketplace. Tyto virtuální počítače mají verze Windows i Linux. Nainstalují se Microsoft R Open, Microsoft ML Server, Anaconda, Jupyter a další nástroje, které jsou připravené k přechodu. Vyvolejte v malém R nebo Pythonu, abyste mohli vizualizovat data a sdílet přehledy se svými kolegy.

Pokud potřebujete provést další analýzu, můžete použít nástroje pro datové vědy Apache, jako je Spark, Hadoop a další, prostřednictvím HDInsight nebo datacihly. Tyto další informace použijte v případě, kdy je potřeba analýzu provést pravidelně a chcete pracovní postup automatizovat. To je užitečné také pro živou analýzu velkých datových sad.

Jakmile najdete něco zajímavého, je nutné prezentovat výsledky. Mnoho Pojistní matematici začne tím, že se postará o výsledky vzorů a připojíte je do Excelu a vytvoříte grafy, grafy a další vizualizace. Pokud chcete něco, co má taky dobrým rozhraním pro přechod na data, podívejte se na [Power BI](https://docs.microsoft.com/power-bi/?WT.mc_id=riskmodel-docs-scseely). Power BI může udělat některé skvělé vizualizace, zobrazit zdrojová data a umožňuje vysvětlovat data čtenářům prostřednictvím přidání [seřazených a pokomentovaných záložek](https://docs.microsoft.com/power-bi/desktop-bookmarks?WT.mc_id=riskmodel-docs-scseely).

## <a name="data-retention"></a>Uchovávání dat

Většina dat, která do systému přinesete, musí být zachována pro budoucí audity. Požadavky na uchovávání dat obvykle mají rozsah 7 až 10 let, ale požadavky se liší. Minimální doba uchovávání zahrnuje:

- Snímek původních vstupů do modelu. Patří sem prostředky, závazky, předpoklady, ESGs a další vstupy.
- Snímek finálních výstupů. To zahrnuje všechna data, která se používají k vytváření sestav prezentovaných regulativním úřadům.
- Další důležité, mezilehlé výsledky. Auditor bude klást důvody, proč byl model vytvořen s nějakým výsledkem. Je nutné si zachovávat informace o tom, proč model provedl určité volby, nebo který byl vytvořen s konkrétními čísly. Mnoho pojistitelů si zvolí, aby byly binární soubory použity pro vytváření konečných výstupů z původních vstupů. Po zobrazení dotazu pak znovu spustí model, aby se získala nová kopie mezilehlých výsledků. Pokud se výstupy shodují, měly by mezilehlé soubory také obsahovat vysvětlení, která potřebují.

Během spuštění modelu Pojistní matematici používat mechanismy pro doručování dat, které mohou zpracovávat zatížení požadavků od spuštění. Po dokončení běhu a data už nejsou potřeba, zachovávají některá data. Přinejmenším by měl pojistitel zachovat vstupy a konfiguraci modulu runtime pro jakékoli požadavky reprodukovatelnosti. Databáze se uchovávají do záloh v Azure Blob Storage a servery se vypnou. Data v úložišti vysoké rychlosti se také pohybují do levnějšího Blob Storage Azure. Jednou v Blob Storage můžete zvolit datovou vrstvu, která se používá pro každý objekt BLOB: horká, studená nebo archivní. Horké úložiště funguje dobře pro často používané soubory. Studené úložiště je optimalizované pro nečastější přístup k datům. Úložiště archivu je nejvhodnější pro uchovávání auditovaných souborů, ale úspora ceny probíhá s náklady na latenci: latence dat archivované vrstvy se měří v hodinách. Přečtěte si [úložiště objektů BLOB v Azure: horká, studená a archivní úroveň úložiště,](https://docs.microsoft.com/azure/storage/blobs/storage-blob-storage-tiers?WT.mc_id=riskmodel-docs-scseely) abyste plně pochopili různé úrovně úložiště. Data můžete spravovat i z vytváření pomocí odstranění se správou životního cyklu. Identifikátory URI pro objekty blob zůstávají statické, ale pokud je objekt BLOB uložený, získá v průběhu času levnější. Tato funkce bude ukládat spoustu peněz a souvisejícím problémům správou pro mnoho uživatelů Azure Storage. Seznamte se s informacemi o těchto modulech a o tom, jak můžete [Spravovat životní cyklus Azure Blob Storage](https://docs.microsoft.com/azure/storage/common/storage-lifecycle-managment-concepts?WT.mc_id=riskmodel-docs-scseely). Fakt, že můžete soubory automaticky odstranit, je vynikající: znamená to, že nechtěně rozšíříte audit odkazem na soubor, který je mimo rozsah, protože samotný soubor je možné odebrat automaticky.

## <a name="next-steps"></a>Další kroky

Pokud má systém obdržíte za použití místní mřížky, bude implementace této mřížky pravděpodobně spuštěná i v Azure. U některých dodavatelů mají specializované implementace Azure, které běží na velkém měřítku. Jako součást přechodu na Azure můžete také přesunout interní nástroje. Pojistní matematici všude zjistila, že jejich dovednosti v oblasti datové vědy dobře fungují na svém přenosném počítači nebo ve velkém prostředí. Hledejte věci, které váš tým už dělá: Možná máte něco, co používá obsáhlý Learning, ale trvá několik hodin nebo dnů, než se spustí na jednom GPU. Zkuste spustit stejnou úlohu na počítači se 4 koncovými grafickými procesory a podívejte se na časy spuštění. lichá jsou vhodné, abyste viděli významné urychlení pro věci, které už máte.

Při vylepšování se ujistěte, že také vytváříte synchronizaci dat, která zakládá data modelování. Běh modelu nemůže začít, dokud nebudou data připravena. To může zahrnovat přidání nějakého úsilí, abyste odesílali jenom data, která se změnila. Skutečný přístup závisí také na velikosti dat: aktualizace několika MB pravděpodobně není velká, ale snížení počtu gigabajtů při nahrávání bude zrychlit spoustu informací.

### <a name="tutorials"></a>Kurzy

- Vývojáři r: [spuštění paralelní simulace r s Azure Batch](https://docs.microsoft.com/azure/batch/tutorial-r-doazureparallel?WT.mc_id=riskmodel-docs-scseely)
- Kurz k zobrazení způsobu použití funkce Azure k interakci s úložištěm: [nahrání imagí do úložiště objektů BLOB pomocí Azure Functions](https://docs.microsoft.com/azure/functions/tutorial-static-website-serverless-api-with-database?tutorial-step=2&WT.mc_id=riskmodel-docs-scseely)
- ETL pomocí datacihly: [extrakce, transformace a načtení dat pomocí Azure Databricks](https://docs.microsoft.com/azure/azure-databricks/databricks-extract-load-sql-data-warehouse?WT.mc_id=riskmodel-docs-scseely)
- ETL se službou HDInsight: [extrakce, transformace a načtení dat pomocí Apache Hive ve službě Azure HDInsight](https://docs.microsoft.com/azure/hdinsight/hdinsight-analyze-flight-delay-data-linux?toc=%2Fen-us%2Fazure%2Fhdinsight%2Fhadoop%2FTOC.json&amp;bc=%2Fen-us%2Fazure%2Fbread%2Ftoc.json&WT.mc_id=riskmodel-docs-scseely)
- Data Science VM postupy (Linux): [https://docs.microsoft.com/azure/machine-learning/data-science-virtual-machine/linux-dsvm-walkthrough](https://docs.microsoft.com/azure/machine-learning/data-science-virtual-machine/linux-dsvm-walkthrough?WT.mc_id=riskmodel-docs-scseely)
- Data Science VM postupy (Windows): [https://docs.microsoft.com/azure/machine-learning/data-science-virtual-machine/vm-do-ten-things](https://docs.microsoft.com/azure/machine-learning/data-science-virtual-machine/vm-do-ten-things?WT.mc_id=riskmodel-docs-scseely)
