---
title: Úvod do vizuálního vyhledávání v maloobchodě s CosmosDB
author: scseely
ms.author: scseely
ms.date: 11/20/2019
ms.topic: article
ms.service: industry
description: Tento článek vysvětluje fáze migrace infrastruktury elektronického obchodování z místního prostředí do Azure.
ms.openlocfilehash: b43ea305e11ac32da58e4d0521d79f90d5c23d85
ms.sourcegitcommit: 3b175d73a82160c4cacec1ce00c6d804a93c765d
ms.translationtype: MT
ms.contentlocale: cs-CZ
ms.lasthandoff: 02/06/2020
ms.locfileid: "77053143"
---
# <a name="visual-search-overview"></a><span data-ttu-id="c4c24-103">Přehled Vizuální vyhledávání</span><span class="sxs-lookup"><span data-stu-id="c4c24-103">Visual Search Overview</span></span>

## <a name="executive-summary"></a><span data-ttu-id="c4c24-104">Shrnutí</span><span class="sxs-lookup"><span data-stu-id="c4c24-104">Executive Summary</span></span>

<span data-ttu-id="c4c24-105">Umělá logika nabízí potenciál k transformaci maloobchodních prodejů, jak je dnes ví.</span><span class="sxs-lookup"><span data-stu-id="c4c24-105">Artificial Intelligence offers the potential to transform retailing as we know it today.</span></span> <span data-ttu-id="c4c24-106">Je vhodné se domnívat, že maloobchodní prodejci budou vyvíjet architekturu prostředí pro zákazníky podporovanou AI.</span><span class="sxs-lookup"><span data-stu-id="c4c24-106">It is reasonable to believe that retailers will develop a customer experience architecture supported by AI.</span></span> <span data-ttu-id="c4c24-107">Je potřeba, aby platforma rozšířená s AI poskytovala při individuálním přizpůsobení technologie Hyper z tržeb.</span><span class="sxs-lookup"><span data-stu-id="c4c24-107">Some expectations are that a platform enhanced with AI will provide a revenue bump due to hyper personalization.</span></span> <span data-ttu-id="c4c24-108">Digitální obchodování nadále zvýší očekávání zákazníků, preference a chování.</span><span class="sxs-lookup"><span data-stu-id="c4c24-108">Digital commerce continues to heighten customer expectations, preferences and behavior.</span></span> <span data-ttu-id="c4c24-109">Požadavky, jako je zapojení v reálném čase, relevantní doporučení a technologie Hyper-v, představují rychlost a pohodlí při kliknutí na tlačítko.</span><span class="sxs-lookup"><span data-stu-id="c4c24-109">Demands such as real-time engagement, relevant recommendations and hyper-personalization are driving speed and convenience at a click of a button.</span></span> <span data-ttu-id="c4c24-110">Umožnění inteligentních funkcí v aplikacích prostřednictvím přirozeného rozpoznávání řeči, vize atd. umožňuje vylepšení v maloobchodě, která zvyšují hodnotu a zároveň přerušuje způsob, jakým zákazníci Nakupujte.</span><span class="sxs-lookup"><span data-stu-id="c4c24-110">Enabling intelligence in applications through natural speech, vision, etc. enables improvements in retail that will increase value while disrupting how customers shop.</span></span>

<span data-ttu-id="c4c24-111">Tento dokument se zaměřuje na koncept AI **vizuálního vyhledávání** a nabízí několik klíčových důležitých informací o jeho implementaci.</span><span class="sxs-lookup"><span data-stu-id="c4c24-111">This document focuses on the AI  concept of **visual search** and offers a few key considerations on its implementation.</span></span> <span data-ttu-id="c4c24-112">Poskytuje příklad pracovního postupu a mapuje své fáze na relevantní technologie Azure.</span><span class="sxs-lookup"><span data-stu-id="c4c24-112">It provides a workflow example and maps its stages to the relevant Azure technologies.</span></span> <span data-ttu-id="c4c24-113">Koncept je založený na zákazníkovi schopným využít image pořízenou mobilním zařízením nebo na internetu, aby provedla hledání relevantních a/nebo podobných položek v závislosti na úmyslu prostředí.</span><span class="sxs-lookup"><span data-stu-id="c4c24-113">The concept is based on a customer being able to leverage an image taken with their mobile device or located on the internet to conduct a search of relevant and/or like items, depending upon the intention of the experience.</span></span> <span data-ttu-id="c4c24-114">Vizuální vyhledávání proto zlepšuje rychlost z textu s využitím textu na obrázek s více body meta-data, aby bylo možné rychle naplochit dostupné položky.</span><span class="sxs-lookup"><span data-stu-id="c4c24-114">Thus, visual search improves speed from texted entry to an image with multiple meta-data points to quickly surface applicable items available.</span></span>

## <a name="visual-search-engines"></a><span data-ttu-id="c4c24-115">Moduly Vizuální vyhledávání</span><span class="sxs-lookup"><span data-stu-id="c4c24-115">Visual Search Engines</span></span>

<span data-ttu-id="c4c24-116">Vizuální vyhledávací moduly načítají informace pomocí obrázků jako vstupů a často, ale ne výhradně – jako výstup.</span><span class="sxs-lookup"><span data-stu-id="c4c24-116">Visual search engines retrieve information using images as input and often—but not exclusively—as output too.</span></span>

<span data-ttu-id="c4c24-117">Moduly se v maloobchodním průmyslu stanou více a běžnější a z velmi dobrých důvodů:</span><span class="sxs-lookup"><span data-stu-id="c4c24-117">Engines are becoming more and more common in the retail industry, and for very good reasons:</span></span>

- <span data-ttu-id="c4c24-118">Přibližně 75% uživatelů z Internetu vyhledává obrázky nebo videa produktu před zahájením nákupu podle sestavy [eMarketer](https://www.emarketer.com/Report/Visual-Commerce-2017-How-Image-Recognition-Augmentation-Changing-Retail/2002059) publikované v 2017.</span><span class="sxs-lookup"><span data-stu-id="c4c24-118">Around 75% of internet users search for pictures or videos of a product before making a purchase, according to an [Emarketer](https://www.emarketer.com/Report/Visual-Commerce-2017-How-Image-Recognition-Augmentation-Changing-Retail/2002059) report published in 2017.</span></span>
- <span data-ttu-id="c4c24-119">74% výsledků hledání textu je neefektivní, podle [Slyce](https://slyce.it/wp-content/uploads/2015/11/Visual_Search_Technology_and_Market.pdf) (společnost pro vizuální vyhledávání) 2015.</span><span class="sxs-lookup"><span data-stu-id="c4c24-119">74% of consumers also find text searches inefficient, according to [Slyce](https://slyce.it/wp-content/uploads/2015/11/Visual_Search_Technology_and_Market.pdf) (a visual search company) 2015 report.</span></span>

<span data-ttu-id="c4c24-120">Proto by trh pro rozpoznávání imagí měl být více než $25 000 000 000 2019 na základě výzkumu na [trzích &amp; trhů](https://www.marketsandmarkets.com/PressReleases/image-recognition.asp).</span><span class="sxs-lookup"><span data-stu-id="c4c24-120">Therefore, the image recognition market will be worth more than $25 billion by 2019, according to research by [Markets &amp; Markets](https://www.marketsandmarkets.com/PressReleases/image-recognition.asp).</span></span>

<span data-ttu-id="c4c24-121">Technologie už podrží hlavní značky elektronického obchodování, které také významně přispěly k vývoji.</span><span class="sxs-lookup"><span data-stu-id="c4c24-121">The technology has already taken hold with major e-commerce brands, who have also contributed significantly to its development.</span></span> <span data-ttu-id="c4c24-122">Nejvýraznějších prvních přijímají je pravděpodobně:</span><span class="sxs-lookup"><span data-stu-id="c4c24-122">The most prominent early adopters are probably:</span></span>

- <span data-ttu-id="c4c24-123">eBay s jejich Vyhledávání obrázků a "najít na eBay" ve své aplikaci (aktuálně se jedná jenom o mobilní prostředí).</span><span class="sxs-lookup"><span data-stu-id="c4c24-123">eBay with their Image Search and "Find It on eBay" tools in their app (this is currently only a mobile experience).</span></span>
- <span data-ttu-id="c4c24-124">Pinterestu se pomocí nástroje pro vizuální zjišťování objektivu.</span><span class="sxs-lookup"><span data-stu-id="c4c24-124">Pinterest with their Lens visual discovery tool.</span></span>
- <span data-ttu-id="c4c24-125">Microsoft s Vizuální vyhledávání Bingu.</span><span class="sxs-lookup"><span data-stu-id="c4c24-125">Microsoft with Bing Visual Search.</span></span>

## <a name="adopt-and-adapt"></a><span data-ttu-id="c4c24-126">Přijmout a upravit</span><span class="sxs-lookup"><span data-stu-id="c4c24-126">Adopt and Adapt</span></span>

<span data-ttu-id="c4c24-127">Naštěstí nepotřebujete k zisku z vizuálního vyhledávání obrovské množství výpočetní síly.</span><span class="sxs-lookup"><span data-stu-id="c4c24-127">Fortunately, you don't need vast amounts of computing power to profit from visual search.</span></span> <span data-ttu-id="c4c24-128">Všechny firmy s katalogem imagí můžou využít odbornosti Microsoftu, které jsou integrované do svých služeb Azure.</span><span class="sxs-lookup"><span data-stu-id="c4c24-128">Any business with an image catalog can take advantage of Microsoft's AI expertise built into its Azure services.</span></span>

<span data-ttu-id="c4c24-129">[Vizuální vyhledávání Bingu](https://azure.microsoft.com/services/cognitive-services/bing-visual-search/?WT.mc_id=vsearchgio-article-gmarchet) Rozhraní API poskytuje způsob, jak extrahovat kontextové informace z imagí, identifikovat – např. – domácí zařízení, způsob, několik druhů produktů atd.</span><span class="sxs-lookup"><span data-stu-id="c4c24-129">[Bing Visual Search](https://azure.microsoft.com/services/cognitive-services/bing-visual-search/?WT.mc_id=vsearchgio-article-gmarchet) API provides a way to extract context information from images, identifying—for instance—home furnishings, fashion, several kinds of products, etc.</span></span>

<span data-ttu-id="c4c24-130">Budou taky vracet vizuálně podobné obrázky z vlastního katalogu a produkty s relativními nákupními zdroji a související hledání.</span><span class="sxs-lookup"><span data-stu-id="c4c24-130">It will also return visually similar images out of its own catalog, products with relative shopping sources, related searches.</span></span> <span data-ttu-id="c4c24-131">I když vaše společnost není jedním z těchto zdrojů, bude mít omezení za zajímavé účely.</span><span class="sxs-lookup"><span data-stu-id="c4c24-131">While interesting, this will be of limited use if your company is not one of those sources.</span></span>

<span data-ttu-id="c4c24-132">Bing bude také poskytovat:</span><span class="sxs-lookup"><span data-stu-id="c4c24-132">Bing will also provide:</span></span>

- <span data-ttu-id="c4c24-133">Značky, které umožňují prozkoumat objekty nebo koncepty, které se nacházejí v imagi.</span><span class="sxs-lookup"><span data-stu-id="c4c24-133">Tags that allow you to explore objects or concepts found in the image.</span></span>
- <span data-ttu-id="c4c24-134">Ohraničující pole pro oblasti zájmu v obrázku (např. oděvy, položky nábytku).</span><span class="sxs-lookup"><span data-stu-id="c4c24-134">Bounding boxes for regions of interest in the image (e.g. clothing, furniture items).</span></span>

<span data-ttu-id="c4c24-135">Tyto informace můžete využít k tomu, abyste snížili prostor pro hledání (a čas) na katalog produktů společnosti významně a omezili jsme ho na objekty, jako jsou ty v oblasti a kategorii zájmu.</span><span class="sxs-lookup"><span data-stu-id="c4c24-135">You can take that information to reduce the search space (and time) into a company's product catalog significantly, restricting it to objects like those in the region and category of interest.</span></span>

## <a name="implement-your-own"></a><span data-ttu-id="c4c24-136">Implementace vlastního</span><span class="sxs-lookup"><span data-stu-id="c4c24-136">Implement Your Own</span></span>

<span data-ttu-id="c4c24-137">Při implementaci vizuálního vyhledávání je potřeba zvážit několik klíčových komponent:</span><span class="sxs-lookup"><span data-stu-id="c4c24-137">There are a few key components to consider when implementing visual search:</span></span>

- <span data-ttu-id="c4c24-138">Ingestování a filtrování imagí</span><span class="sxs-lookup"><span data-stu-id="c4c24-138">Ingesting and filtering images</span></span>
- <span data-ttu-id="c4c24-139">Metody úložiště a načítání</span><span class="sxs-lookup"><span data-stu-id="c4c24-139">Storage and retrieval techniques</span></span>
- <span data-ttu-id="c4c24-140">Featurization, Encoding nebo "hashing"</span><span class="sxs-lookup"><span data-stu-id="c4c24-140">Featurization, encoding or "hashing"</span></span>
- <span data-ttu-id="c4c24-141">Míry podobnosti nebo vzdálenosti a hodnocení</span><span class="sxs-lookup"><span data-stu-id="c4c24-141">Similarity measures or distances and ranking</span></span>

 ![](./assets/visual-search-use-case-overview/visual-search-pipeline.png)

<span data-ttu-id="c4c24-142">*Obrázek 1: příklad kanálu Vizuální vyhledávání*</span><span class="sxs-lookup"><span data-stu-id="c4c24-142">*Figure 1: Example of Visual Search Pipeline*</span></span>

### <a name="sourcing-the-pictures"></a><span data-ttu-id="c4c24-143">Navýšení obrázků</span><span class="sxs-lookup"><span data-stu-id="c4c24-143">Sourcing the Pictures</span></span>

<span data-ttu-id="c4c24-144">Pokud nevlastníte katalog obrázků, možná budete muset vyškolit algoritmy v otevřených dostupných datových sadách, jako je například [mnist ručně zapsaných](https://www.kaggle.com/zalando-research/fashionmnist) [, hlubokou](http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html) a podobným způsobem.</span><span class="sxs-lookup"><span data-stu-id="c4c24-144">If you do not own a picture catalog, you may need to train the algorithms on openly available data sets, such as fashion [MNIST](https://www.kaggle.com/zalando-research/fashionmnist), deep [fashion](http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html) and similar.</span></span> <span data-ttu-id="c4c24-145">Obsahují několik kategorií produktů a často se používají ke kategorizaci a algoritmům pro vyhledávání v testování obrazu.</span><span class="sxs-lookup"><span data-stu-id="c4c24-145">They contain several categories of products and are commonly used to benchmark image categorization and search algorithms.</span></span>

 ![](./assets/visual-search-use-case-overview/deep-fashion-dataset.png)

<span data-ttu-id="c4c24-146">*Obrázek 2: příklad z datové sady s hloubkovým způsobem*</span><span class="sxs-lookup"><span data-stu-id="c4c24-146">*Figure 2: An Example from The Deep Fashion Dataset*</span></span>

### <a name="filtering-the-images"></a><span data-ttu-id="c4c24-147">Filtrování imagí</span><span class="sxs-lookup"><span data-stu-id="c4c24-147">Filtering the Images</span></span>

<span data-ttu-id="c4c24-148">Většina datových sad srovnávacích testů – například ty, které byly zmíněny před – již byly zpracovány předem.</span><span class="sxs-lookup"><span data-stu-id="c4c24-148">Most benchmark datasets - such as those mentioned before - have already been pre-processed.</span></span>

<span data-ttu-id="c4c24-149">Pokud vytváříte vlastní, budete mít přinejmenším v tom, že mají všechny obrázky stejnou velikost, hlavně vynásobené vstupem, pro který je váš model vyškolený.</span><span class="sxs-lookup"><span data-stu-id="c4c24-149">If you are building your own, at a minimum you will want the images to all have the same size, mostly dictated by the input that your model is trained for.</span></span>

<span data-ttu-id="c4c24-150">V mnoha případech je nejlepší také normalizovat světlost imagí.</span><span class="sxs-lookup"><span data-stu-id="c4c24-150">In many cases, it is best also to normalize the luminosity of the images.</span></span> <span data-ttu-id="c4c24-151">V závislosti na úrovni podrobností hledání může být barva také redundantní informace, takže snížení na černou a bílou vám pomůže s časy zpracování.</span><span class="sxs-lookup"><span data-stu-id="c4c24-151">Depending on the detail level of your search, color may also be redundant information, so reducing to black and white will help with processing times.</span></span>

<span data-ttu-id="c4c24-152">A ne alespoň, datová sada obrázku by měla být vyrovnávána napříč různými třídami, které představuje.</span><span class="sxs-lookup"><span data-stu-id="c4c24-152">Last but not least, the image dataset should be balanced across the different classes it represents.</span></span>

### <a name="image-database"></a><span data-ttu-id="c4c24-153">Databáze obrázků</span><span class="sxs-lookup"><span data-stu-id="c4c24-153">Image Database</span></span>

<span data-ttu-id="c4c24-154">Datová vrstva je zvlášť jemná komponenta vaší architektury.</span><span class="sxs-lookup"><span data-stu-id="c4c24-154">The data layer is a particularly delicate component of your architecture.</span></span> <span data-ttu-id="c4c24-155">Bude obsahovat:</span><span class="sxs-lookup"><span data-stu-id="c4c24-155">It will contain:</span></span>

- <span data-ttu-id="c4c24-156">Image</span><span class="sxs-lookup"><span data-stu-id="c4c24-156">Images</span></span>
- <span data-ttu-id="c4c24-157">Všechna metadata o obrázcích (velikost, značky, SKU produktů, popis)</span><span class="sxs-lookup"><span data-stu-id="c4c24-157">Any metadata about the images (size, tags, product SKUs, description)</span></span>
- <span data-ttu-id="c4c24-158">Data generovaná modelem strojového učení (například číselná vektor 4096 prvku na obrázek)</span><span class="sxs-lookup"><span data-stu-id="c4c24-158">Data generated by the machine learning model (for instance a 4096-element numerical vector  per image)</span></span>

<span data-ttu-id="c4c24-159">Při načítání imagí z různých zdrojů nebo použití několika modelů strojového učení za účelem optimálního výkonu se struktura dat změní.</span><span class="sxs-lookup"><span data-stu-id="c4c24-159">As you retrieve images from different sources or use several machine learning models for optimal performance, the structure of the data will change.</span></span> <span data-ttu-id="c4c24-160">Je proto důležité zvolit technologii nebo kombinaci, která může pracovat s částečně strukturovanými daty a bez pevného schématu.</span><span class="sxs-lookup"><span data-stu-id="c4c24-160">It is therefore important to choose a technology or combination that can deal with semi-structured data and no fixed schema.</span></span>

<span data-ttu-id="c4c24-161">Možná budete chtít vyžadovat minimální počet užitečných datových bodů (například identifikátor obrázku nebo klíč, SKU produktu, popis, pole značka).</span><span class="sxs-lookup"><span data-stu-id="c4c24-161">You may also want to require a minimum number of useful data points (e.g. an image identifier or key, a product sku, a description, a tag field).</span></span>

<span data-ttu-id="c4c24-162">[Azure CosmosDB](https://azure.microsoft.com/services/cosmos-db/?WT.mc_id=vsearchgio-article-gmarchet) nabízí požadovanou flexibilitu a řadu přístupových mechanismů pro aplikace, které jsou na ní postavené (což vám pomůže při hledání v katalogu).</span><span class="sxs-lookup"><span data-stu-id="c4c24-162">[Azure CosmosDB](https://azure.microsoft.com/services/cosmos-db/?WT.mc_id=vsearchgio-article-gmarchet) offers the required flexibility and a variety of access mechanisms for applications built on top of it (which will help with your catalog search).</span></span> <span data-ttu-id="c4c24-163">Jedna z nich však musí být opatrní, aby vystavila nejlepší poměr ceny a výkonu.</span><span class="sxs-lookup"><span data-stu-id="c4c24-163">However, one has to be careful to drive the best price/performance.</span></span> <span data-ttu-id="c4c24-164">CosmosDB umožňuje uložit přílohy dokumentů, ale celkový limit pro každý účet může být nákladný.</span><span class="sxs-lookup"><span data-stu-id="c4c24-164">CosmosDB allows document attachments to be stored, but there is a total limit per account and it may be a costly proposition.</span></span> <span data-ttu-id="c4c24-165">Běžný postup je uložit skutečné soubory imagí do objektů BLOB a vložit na ně odkazy v databázi.</span><span class="sxs-lookup"><span data-stu-id="c4c24-165">It is common practice to store the actual image files in blobs and insert a link to them in the database.</span></span> <span data-ttu-id="c4c24-166">V případě CosmosDB to znamená vytvoření dokumentu, který obsahuje vlastnosti katalogu přidružené k této imagi (SKU, značky atd.), a přílohu, která obsahuje adresu URL souboru obrázku (např. v Azure Blob Storage, OneDrive atd.).</span><span class="sxs-lookup"><span data-stu-id="c4c24-166">In the case of CosmosDB this implies creating a document that contains the catalog properties associated to that image (sku, tag etc.) and an attachment that contains the URL of the image file (e.g. on Azure blob storage, OneDrive etc).</span></span>

 ![](./assets/visual-search-use-case-overview/cosmosdb-data-model.png)

<span data-ttu-id="c4c24-167">*Obrázek 3: CosmosDB hierarchické modely prostředků*</span><span class="sxs-lookup"><span data-stu-id="c4c24-167">*Figure 3: CosmosDB Hierarchical Resource Model*</span></span>

<span data-ttu-id="c4c24-168">Pokud máte v úmyslu využít globální distribuci Cosmos DB, pamatujte na to, že se budou replikovat dokumenty a přílohy, ale ne propojené soubory.</span><span class="sxs-lookup"><span data-stu-id="c4c24-168">If you plan to take advantage of the global distribution of Cosmos DB, note that it will replicate the documents and attachments, but not the linked files.</span></span> <span data-ttu-id="c4c24-169">Možná budete chtít zvážit síť pro distribuci obsahu.</span><span class="sxs-lookup"><span data-stu-id="c4c24-169">You may want to consider a content distribution network for those.</span></span>

<span data-ttu-id="c4c24-170">Další použitelné technologie jsou kombinací Azure SQL Database (Pokud je pevné schéma přijatelné) a objektů blob, nebo tabulek Azure a objektů BLOB pro levné a rychlé ukládání a načítání.</span><span class="sxs-lookup"><span data-stu-id="c4c24-170">Other applicable technologies are a combination of Azure SQL Database (if fixed schema is acceptable) and blobs, or even Azure Tables and blobs for inexpensive and fast storage and retrieval.</span></span>

### <a name="feature-extraction-amp-encoding"></a><span data-ttu-id="c4c24-171">&amp; kódování pro extrakci funkcí</span><span class="sxs-lookup"><span data-stu-id="c4c24-171">Feature Extraction &amp; Encoding</span></span>

<span data-ttu-id="c4c24-172">Proces kódování extrahuje funkce nejdůležitějšími z obrázků v databázi a mapuje je na zhuštěné vektory "funkce" (vektor s mnoha nulami), které mohou mít tisíce komponent.</span><span class="sxs-lookup"><span data-stu-id="c4c24-172">The encoding process extracts salient features from pictures in the database and maps each of them to a sparse "feature" vector (a vector with many zeros) that can have thousands of components.</span></span> <span data-ttu-id="c4c24-173">Tento vektor je numerická reprezentace funkcí (např. hrany, tvary), které charakterizují obrázek – podobají na kód.</span><span class="sxs-lookup"><span data-stu-id="c4c24-173">This vector is a numerical representation of the features (e.g. edges, shapes) that characterize the picture – akin to a code.</span></span>

<span data-ttu-id="c4c24-174">Techniky extrakce funkcí obvykle používají _mechanismy přenosu_.</span><span class="sxs-lookup"><span data-stu-id="c4c24-174">Feature extraction techniques typically use _transfer learning mechanisms_.</span></span> <span data-ttu-id="c4c24-175">K tomu dojde, když vyberete předem proučenou neuronové síť, spustíte každý z nich a uložíte vektor funkce, který jste v databázi imagí vygenerovali zpátky.</span><span class="sxs-lookup"><span data-stu-id="c4c24-175">This occurs when you select a pre-trained neural network, run each image through it and store the feature vector  produced back in your image database.</span></span> <span data-ttu-id="c4c24-176">Tímto způsobem můžete "přenést" učení od toho, kdo tuto síť vyškole.</span><span class="sxs-lookup"><span data-stu-id="c4c24-176">In that way, you "transfer" the learning from whoever trained the network.</span></span> <span data-ttu-id="c4c24-177">Společnost Microsoft vyvinula a publikovala několik předem vyškolených sítí, které byly široce používány pro úlohy rozpoznávání imagí, jako je například [ResNet50](https://www.kaggle.com/keras/resnet50).</span><span class="sxs-lookup"><span data-stu-id="c4c24-177">Microsoft has developed and published several pre-trained networks that have been widely used for image recognition tasks, such as [ResNet50](https://www.kaggle.com/keras/resnet50).</span></span>

<span data-ttu-id="c4c24-178">V závislosti na síti neuronové bude mít vektor funkcí víc nebo méně dlouhých a řídkých, takže požadavky na paměť a úložiště se budou lišit.</span><span class="sxs-lookup"><span data-stu-id="c4c24-178">Depending on the neural network, the feature vector will be more or less long and sparse, hence the memory and storage requirements will vary.</span></span>

<span data-ttu-id="c4c24-179">Můžete také zjistit, že různé sítě se vztahují na různé kategorie, takže implementace vizuálního vyhledávání může ve skutečnosti generovat vektory různých velikostí.</span><span class="sxs-lookup"><span data-stu-id="c4c24-179">Also, you may find that different networks are applicable to different categories, hence an implementation of visual search may actually generate feature vectors of varying size.</span></span>

<span data-ttu-id="c4c24-180">Předem připravené sítě neuronové se poměrně snadno používají, ale nemusí být efektivní pro vlastní model vyškolený v katalogu imagí.</span><span class="sxs-lookup"><span data-stu-id="c4c24-180">Pre-trained neural networks are relatively easy to use but may not be as efficient a custom model trained on your image catalog.</span></span> <span data-ttu-id="c4c24-181">Tyto předem připravené sítě jsou obvykle navržené pro klasifikaci srovnávacích datových sad místo hledání ve vaší konkrétní kolekci imagí.</span><span class="sxs-lookup"><span data-stu-id="c4c24-181">Those pre-trained networks are typically designed for classification of benchmark datasets rather than search on your specific collection of images.</span></span>

<span data-ttu-id="c4c24-182">Můžete je chtít upravit a znovu vytvořit, aby vybíraly předpověď kategorií i hustý vektor (tj. menší, nikoli zhuštěný), což bude velmi užitečné omezit prostor pro hledání a snížit požadavky na paměť a úložiště.</span><span class="sxs-lookup"><span data-stu-id="c4c24-182">You may want to modify and retrain them so they produce both a category prediction and a dense (i.e. smaller, not sparse) vector, which will be very useful to restrict the search space, reduce memory and storage requirements.</span></span> <span data-ttu-id="c4c24-183">Binární vektory lze použít a často se označují jako " [sémantická hodnota hash](https://www.cs.utoronto.ca/~rsalakhu/papers/semantic_final.pdf)" – termín odvozený od technik kódování a načítání dokumentů.</span><span class="sxs-lookup"><span data-stu-id="c4c24-183">Binary vectors can be used and are often referred to as " [semantic hash](https://www.cs.utoronto.ca/~rsalakhu/papers/semantic_final.pdf)" – a term derived from document encoding and retrieval techniques.</span></span> <span data-ttu-id="c4c24-184">Binární reprezentace usnadňuje další výpočty.</span><span class="sxs-lookup"><span data-stu-id="c4c24-184">The binary representation simplifies further calculations.</span></span>

 ![](./assets/visual-search-use-case-overview/resnet-modifications.png)

<span data-ttu-id="c4c24-185">*Obrázek 4: úpravy ResNet pro Vizuální vyhledávání – F. Yang et al., 2017*</span><span class="sxs-lookup"><span data-stu-id="c4c24-185">*Figure 4: Modifications to ResNet for Visual Search – F. Yang et al., 2017*</span></span>

<span data-ttu-id="c4c24-186">Bez ohledu na to, jestli si zvolíte předem připravené modely nebo vyvíjíte vlastní, budete se muset rozhodnout, kde spustit featurization a/nebo školení samotného modelu.</span><span class="sxs-lookup"><span data-stu-id="c4c24-186">Whether you choose pre-trained models or to develop your own, you will still need to decide where to run the featurization and/or training of the model itself.</span></span>

<span data-ttu-id="c4c24-187">Azure nabízí několik možností: virtuální počítače, Azure Batch, [Batch AI](https://azure.microsoft.com/services/batch-ai/?WT.mc_id=vsearchgio-article-gmarchet), clustery datacihly.</span><span class="sxs-lookup"><span data-stu-id="c4c24-187">Azure offers several options: VMs, Azure Batch, [Batch AI](https://azure.microsoft.com/services/batch-ai/?WT.mc_id=vsearchgio-article-gmarchet), Databricks clusters.</span></span> <span data-ttu-id="c4c24-188">Ve všech případech ale nejlepší cena/výkon je dána pomocí GPU.</span><span class="sxs-lookup"><span data-stu-id="c4c24-188">In all cases, however, the best price/performance is given by the use of GPUs.</span></span>

<span data-ttu-id="c4c24-189">Společnost Microsoft také nedávno oznámila dostupnost FPGA pro rychlé výpočty za zlomek nákladů GPU (projekt [Brainwave](https://www.microsoft.com/research/blog/microsoft-unveils-project-brainwave/?WT.mc_id=vsearchgio-article-gmarchet)).</span><span class="sxs-lookup"><span data-stu-id="c4c24-189">Microsoft has also recently announced the availability of FPGAs for fast computation at a fraction of the GPU cost (project [Brainwave](https://www.microsoft.com/research/blog/microsoft-unveils-project-brainwave/?WT.mc_id=vsearchgio-article-gmarchet)).</span></span> <span data-ttu-id="c4c24-190">V době psaní však je tato nabídka omezená na určité síťové architektury, takže budete muset svůj výkon vyhodnotit pečlivě.</span><span class="sxs-lookup"><span data-stu-id="c4c24-190">However, at the time of writing, this offering is limited to certain network architectures, so you will need to evaluate their performance closely.</span></span>

### <a name="similarity-measure-or-distance"></a><span data-ttu-id="c4c24-191">Míra podobnosti nebo vzdálenost</span><span class="sxs-lookup"><span data-stu-id="c4c24-191">Similarity Measure or Distance</span></span>

<span data-ttu-id="c4c24-192">Pokud jsou obrázky reprezentovány ve vektorovém prostoru funkce, hledání podobnosti se projeví jako otázka definování míry vzdálenosti mezi body v takovém prostoru.</span><span class="sxs-lookup"><span data-stu-id="c4c24-192">When the images are represented in the feature vector space, finding similarities becomes a question of defining a distance measure between points in such space.</span></span> <span data-ttu-id="c4c24-193">Po definování vzdálenosti můžete vypočítat clustery podobných obrázků nebo definovat matice podobnosti.</span><span class="sxs-lookup"><span data-stu-id="c4c24-193">Once a distance is defined, you can compute clusters of similar images and/or define similarity matrices.</span></span> <span data-ttu-id="c4c24-194">V závislosti na vybrané metrikě vzdálenosti se výsledky můžou lišit.</span><span class="sxs-lookup"><span data-stu-id="c4c24-194">Depending on the distance metric selected, the results may vary.</span></span> <span data-ttu-id="c4c24-195">Nejběžnější míry Euclidean vzdálenosti nad vektory reálného čísla je například snadno pochopit: zachycuje velikost vzdálenosti.</span><span class="sxs-lookup"><span data-stu-id="c4c24-195">The most common Euclidean distance measure over real-number vectors, for instance, is easy to understand: it captures the magnitude of the distance.</span></span> <span data-ttu-id="c4c24-196">Je ale spíše neefektivní z podmínek výpočtu.</span><span class="sxs-lookup"><span data-stu-id="c4c24-196">However, it is rather inefficient in terms of computation.</span></span>

<span data-ttu-id="c4c24-197">[Kosinusová](https://en.wikipedia.org/wiki/Cosine_similarity) vzdálenost se často používá k zachycení orientace vektoru namísto jeho velikosti.</span><span class="sxs-lookup"><span data-stu-id="c4c24-197">[Cosine](https://en.wikipedia.org/wiki/Cosine_similarity) distance is often used to capture the orientation of the vector, rather than its magnitude.</span></span>

<span data-ttu-id="c4c24-198">Alternativy, jako je [Hammingá](https://en.wikipedia.org/wiki/Hamming_distance) vzdálenost přes binární reprezentace, představují určitou přesnost pro efektivitu a rychlost.</span><span class="sxs-lookup"><span data-stu-id="c4c24-198">Alternatives such as [Hamming](https://en.wikipedia.org/wiki/Hamming_distance) distance over binary representations trade some accuracy for efficiency and speed.</span></span>

<span data-ttu-id="c4c24-199">Kombinace velikosti vektoru a míry vzdálenosti určuje, jak se bude vyhodnocovat výpočetní výkon a velký objem paměti.</span><span class="sxs-lookup"><span data-stu-id="c4c24-199">The combination of vector size and distance measure will determine how computationally intensive and memory intensive the search will be.</span></span>

### <a name="search-amp-ranking"></a><span data-ttu-id="c4c24-200">Hledat &amp; hodnocení</span><span class="sxs-lookup"><span data-stu-id="c4c24-200">Search &amp; Ranking</span></span>

<span data-ttu-id="c4c24-201">Po definování podobnosti musíme navrhnout efektivní metodu pro načtení nejbližších N položek předaných jako vstup a pak vracet seznam identifikátorů.</span><span class="sxs-lookup"><span data-stu-id="c4c24-201">Once similarity is defined, we need to devise an efficient method to retrieve the closest N items to the one passed as input, then return a list of identifiers.</span></span> <span data-ttu-id="c4c24-202">Tato možnost se označuje také jako "hodnocení obrázku".</span><span class="sxs-lookup"><span data-stu-id="c4c24-202">This is also known as "image ranking".</span></span> <span data-ttu-id="c4c24-203">V případě velkých datových sad je čas na výpočet každé vzdálenosti zakázán, takže použijeme přibližné algoritmy s nejbližším sousedem.</span><span class="sxs-lookup"><span data-stu-id="c4c24-203">On a large data set, the time to compute every distance is prohibitive, so we use approximate nearest-neighbor algorithms.</span></span> <span data-ttu-id="c4c24-204">Pro ty existují některé knihovny open source, takže nebudete muset vytvářet kód od začátku.</span><span class="sxs-lookup"><span data-stu-id="c4c24-204">Several open source libraries exist for those, so you won't have to code them from scratch.</span></span>

<span data-ttu-id="c4c24-205">Požadavky na paměť a výpočet budou nakonec určovat volbu technologie nasazení pro trained model a také vysokou dostupnost.</span><span class="sxs-lookup"><span data-stu-id="c4c24-205">Finally, memory and computation requirements will determine the choice of deployment technology for the trained model, as well high availability.</span></span> <span data-ttu-id="c4c24-206">Prostor pro hledání se obvykle dělí na oddíly a několik instancí algoritmu hodnocení se spustí paralelně.</span><span class="sxs-lookup"><span data-stu-id="c4c24-206">Typically, the search space will be partitioned, and several instances of the ranking algorithm will run in parallel.</span></span> <span data-ttu-id="c4c24-207">Jedna z možností, která umožňuje škálovatelnost a dostupnost, je clustery [Azure Kubernetes](https://azure.microsoft.com/services/container-service/kubernetes/?WT.mc_id=vsearchgio-article-gmarchet) .</span><span class="sxs-lookup"><span data-stu-id="c4c24-207">One option that allows for scalability and availability is [Azure Kubernetes](https://azure.microsoft.com/services/container-service/kubernetes/?WT.mc_id=vsearchgio-article-gmarchet) clusters.</span></span> <span data-ttu-id="c4c24-208">V takovém případě je vhodné nasadit model hodnocení mezi několik kontejnerů (zpracováním oddílu každého hledaného prostoru) a několika uzly (pro vysokou dostupnost).</span><span class="sxs-lookup"><span data-stu-id="c4c24-208">In that case it is advisable to deploy the ranking model across several containers (handling a partition of the search space each) and several nodes (for high availability).</span></span>

## <a name="next-steps"></a><span data-ttu-id="c4c24-209">Další kroky</span><span class="sxs-lookup"><span data-stu-id="c4c24-209">Next steps</span></span>

<span data-ttu-id="c4c24-210">Implementace vizuálního vyhledávání nemusí být složitá.</span><span class="sxs-lookup"><span data-stu-id="c4c24-210">Implementing visual search need not be complex.</span></span> <span data-ttu-id="c4c24-211">Můžete využít Bing nebo sestavit vlastní se službami Azure a těžit z nástrojů pro vyhledávání a používání společnosti Microsoft.</span><span class="sxs-lookup"><span data-stu-id="c4c24-211">You can use Bing or build your own with Azure services, while benefiting from Microsoft's AI research and tools.</span></span>

### <a name="trial"></a><span data-ttu-id="c4c24-212">Zkušební verze</span><span class="sxs-lookup"><span data-stu-id="c4c24-212">Trial</span></span>

- <span data-ttu-id="c4c24-213">Vyzkoušejte si [konzolu pro testování vizuální vyhledávání API](https://dev.cognitive.microsoft.com/docs/services/878c38e705b84442845e22c7bff8c9ac)</span><span class="sxs-lookup"><span data-stu-id="c4c24-213">Try out the [Visual Search API Testing Console](https://dev.cognitive.microsoft.com/docs/services/878c38e705b84442845e22c7bff8c9ac)</span></span>

### <a name="develop"></a><span data-ttu-id="c4c24-214">Vyvinout</span><span class="sxs-lookup"><span data-stu-id="c4c24-214">Develop</span></span>

- <span data-ttu-id="c4c24-215">Pokud chcete začít vytvářet vlastní službu, přečtěte si téma [rozhraní API pro vizuální vyhledávání Bingu Overview](https://docs.microsoft.com/azure/cognitive-services/bing-visual-search/overview/?WT.mc_id=vsearchgio-article-gmarchet) .</span><span class="sxs-lookup"><span data-stu-id="c4c24-215">To begin creating a customized service, see [Bing Visual Search API Overview](https://docs.microsoft.com/azure/cognitive-services/bing-visual-search/overview/?WT.mc_id=vsearchgio-article-gmarchet)</span></span>
- <span data-ttu-id="c4c24-216">Chcete-li vytvořit první požadavek, přečtěte si téma [C#](https://docs.microsoft.com/azure/cognitive-services/bing-visual-search/quickstarts/csharp) rychlý start: | [Java](https://docs.microsoft.com/azure/cognitive-services/bing-visual-search/quickstarts/java) | [Node. js](https://docs.microsoft.com/azure/cognitive-services/bing-visual-search/quickstarts/nodejs) | [Python](https://docs.microsoft.com/azure/cognitive-services/bing-visual-search/quickstarts/python)</span><span class="sxs-lookup"><span data-stu-id="c4c24-216">To create your first request, see the quickstarts: [C#](https://docs.microsoft.com/azure/cognitive-services/bing-visual-search/quickstarts/csharp) | [Java](https://docs.microsoft.com/azure/cognitive-services/bing-visual-search/quickstarts/java) | [node.js](https://docs.microsoft.com/azure/cognitive-services/bing-visual-search/quickstarts/nodejs) | [Python](https://docs.microsoft.com/azure/cognitive-services/bing-visual-search/quickstarts/python)</span></span>
- <span data-ttu-id="c4c24-217">Seznamte se s [referenčními informacemi k rozhraní API pro vizuální vyhledávání](https://aka.ms/bingvisualsearchreferencedoc).</span><span class="sxs-lookup"><span data-stu-id="c4c24-217">Familiarize yourself with the [Visual Search API Reference](https://aka.ms/bingvisualsearchreferencedoc).</span></span>

### <a name="background"></a><span data-ttu-id="c4c24-218">Podrobnosti</span><span class="sxs-lookup"><span data-stu-id="c4c24-218">Background</span></span>

- <span data-ttu-id="c4c24-219">[Segmentace obrázků s hloubkovým učením](https://www.microsoft.com/developerblog/2018/04/18/deep-learning-image-segmentation-for-ecommerce-catalogue-visual-search/?WT.mc_id=vsearchgio-article-gmarchet): Microsoft paper popisuje proces oddělení imagí z pozadí.</span><span class="sxs-lookup"><span data-stu-id="c4c24-219">[Deep Learning Image Segmentation](https://www.microsoft.com/developerblog/2018/04/18/deep-learning-image-segmentation-for-ecommerce-catalogue-visual-search/?WT.mc_id=vsearchgio-article-gmarchet): Microsoft paper describes the process of separating images from backgrounds</span></span>
- <span data-ttu-id="c4c24-220">[Vizuální vyhledávání na adrese eBay](https://arxiv.org/abs/1706.03154): Cornell University Research</span><span class="sxs-lookup"><span data-stu-id="c4c24-220">[Visual Search at Ebay](https://arxiv.org/abs/1706.03154): Cornell University research</span></span>
- <span data-ttu-id="c4c24-221">[Vizuální zjišťování na Pinterestu](https://arxiv.org/abs/1702.04680) Cornell University Research</span><span class="sxs-lookup"><span data-stu-id="c4c24-221">[Visual Discovery at Pinterest](https://arxiv.org/abs/1702.04680) Cornell University research</span></span>
- <span data-ttu-id="c4c24-222">[Sémantické hashing](https://www.cs.utoronto.ca/~rsalakhu/papers/semantic_final.pdf) Univerzita Toronto Research</span><span class="sxs-lookup"><span data-stu-id="c4c24-222">[Semantic Hashing](https://www.cs.utoronto.ca/~rsalakhu/papers/semantic_final.pdf) University of Toronto research</span></span>

<span data-ttu-id="c4c24-223">_Tento článek vytvořila služba Giovanni Marchetti a Mariya Zorotovich._</span><span class="sxs-lookup"><span data-stu-id="c4c24-223">_This article was authored by Giovanni Marchetti and Mariya Zorotovich._</span></span>